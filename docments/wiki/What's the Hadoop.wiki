 == 第一章 绪论 == 
  `Hadoop并不是凭空想象出来的，它的出现源于人们创建和使用的数据量的爆炸性增长. 章首先探讨Hadoop出现的背景，并详细讲解Hadoop想要解决的问题和决定其最终设计的内在驱动因素。`
* 本章包括以下内容
  # 概述大数据革命
  # 讲解Hadoop是什么以及如何从数据中获取有价值信息。
  # 探秘云计算并了解AWS的功能
  # 概述本书其余章节内容

=== 大数据处理 ===
* 数据量
  我们当前所处的环境中，几乎所有技术都是以数据为核心，数据量之庞大难以想象。
* 数据增长率
  不仅数据总量在迅速增长，数据生成速率也在不断增加。
* 数据利用
  这样大量的数据面前，如何快速的提取出需要的数据，成了一个大问题。

=== 数据的价值 ===
* 数据采集量
  只有在数据量足够大的时候，某些问题才变得有意义。(比如：针对个人感兴趣的内容推送广告)
* 成本
  只有在投入数据分析成本远远小于数据价值的时候，大数据才有意义。
* 效率
  数据处理效率必须要高，否则，如果当数据处理完成后，数据已经没有使用价值的话，也就没有任何意义了。
* 存储介质
  为了满足数据库中最大数据的需要，可能需要重新审视之前关于数据库形式活着其中数据结构的假设。

        综上所述：足够大的数据集以及灵活的工具可以使之前无法想象的问题得到解答。
        
=== 受众人群 ===
  `早期，大数据处理不仅成本高而且实现困难，超出了中小企业的能力范围。同时，比大数据处理技术应用更为广泛的数据挖掘方法已经存在了很长一段时间，但是在大型企业和政府部门之外从没有真正得到推广。`
  
==== Hadoop 系统基础的背景 ====
        
        现有数据处理系统扩展为大数据处理系统非常困难，因为数据处理系统的处理能力一直受限于单台计算机的极限运算能力。
        
* 经典的数据处理系统
  # 向上扩展<br/>
     将数据处理任务迁移到更大的服务器或者存储矩阵（成本很高）<br/>
     `优点：方式简单、架构不会改变`<br/>
     `缺点：扩展简单却有极限，费用高`<br/>
  # 向外扩展<br/>
     早期向外扩展的方法是，将数据分发给多台机器处理<br/>
     `优点：成本低`<br/>
     `缺点：扩展复杂，需要软件架构支持`<br/>
* 制约因素
  # 不论向上还是向外扩展，都需要研发人员极大的支持，就算是向上扩展，当CPU增多时，要想在整个数据处理任务执行期间保持系统高效运作，都是需要付出极大的努力。
  # CPU的速度远远高于硬盘，现代CPU的速度是20年前的数百万倍，而硬盘只提高了千倍甚至百倍，存储成为了系统中最大的瓶颈。

==== Hadoop 到底是什么 ====
# Hadoop起源于Google, Google于03、04年发表了两篇描述Google技术的学术论文：
  * GFS: http://research.google.com/archive/gfs.html
  * MapReduce: http://research.google.com/archive/mapreduce.html
# Hadoop的组成部分
  * HDFS
    HDFS是一个可以存储极大数据集的文件系统，它是通过向外扩展方式构建的主要集群。以时延为代价对吞吐量进行了优化，并且通过副本替换冗余达到了高可靠性。
  * MapReduce
    这是一个数据处理范式，它规范了数据在两个处理阶段(Map和Reduce)的输入、输出，并将其应用于任意规模的大数据集。
# 公共构建模块<br/>
  HDFS和MapReduce都体现了一些上一节描述的体系原则。特别是：
  * 都是面向廉价服务器集群设计的。
  * 都是通过增加更多的服务器来实现系统扩展（向外）。
  * 都包含了检测和处理故障的机制。
  * 都透明地提供了许多服务，从而使用户可以更专注于手头的问题。
  * 都采用了同样的架构，其中驻留在物理服务器上的软件集群控制着系统运行的各个方面。
# HDFS<br/>
  HDFS（Hadoop Distributed File System，Hadoop分布式文件系统）<br/>
  HDFS是一个不具备POSIX兼容性的文件系统。<br/>
  HDFS主要特点如下：
  * HDFS通常以最小64MB的数据块存储文件，这比之前多数文件系统中的4KB-32KB分块大得多。
  * HDFS在时延的基础上对吞吐量进行了优化，它能够高效处理对大文件的读请求流，但不擅长对众多小文件的定位请求。
  * HDFS对普遍的“一次写入，多次读取”的工作负载进行了优化。
  * 每个存储节点上运行着一个成为DataNode的进程，它管理着相应主机上的所有数据块。
  * 与磁盘阵列中设置物理冗余来处理磁盘故障或类似策略不同，HDFS使用副本来处理故障。每个由文件组成的数据块存储在集群中的多个节点，HDFS的NameNode不断地见识各个DataNode发来的报告，以确保发生故障时，任意数据块的副本数量都大于用户配置的复制因子。
# MapReduce
  * 在函数式编程语言中，map和reduce函数被用于对输入数据列表进行操作。
  * 分而治之：在理想情况下，一个需要运行1000分钟的任务可以通过分解成1000个并行的子任务，在1分钟内即可完成。
  
        MapReduce是一个基于上述原理的处理范式，它实现了从源数据集到结果数据集的一系列转换。在最简单的情况下，作业的输入数据做为map函数的输入，所得到的临时数据作为reduce函数的输入。开发人员只需定义数据转换形式，Hadoop的MapReduce作业负责并行地对集群中的数据实施所需转换。
        Hadoop为map和reduce函数提供了一个标准规范(接口)，上述规范的具体实现通常被称为mapper和reducer。一个典型的MapReduce作业包括多个mapper和reducer，通常这些mapper和reducer并不是很简单。
  
  
