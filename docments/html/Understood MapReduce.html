<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<link rel="Stylesheet" type="text/css" href="style.css">
<title>Understood MapReduce</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head>
<body>

<h3 id="toc_0.0.1" class="justcenter">理解MapReduce</h3>
<blockquote>
本章目的：<br/>
理解键值对为何可以成为Hadoop任务的基础<br/>
了解MapReduce作业的多个阶段<br/>
详细探讨map、reduce以及可选组合阶段的工作原理<br/>
学习Hadoop Java API，并用它开发一些简单的MapReduce作业<br/>
了解Hadoop的输入和输出<br/>
</blockquote>
        
<h4 id="toc_0.0.1.1">键值对</h4>
<ul>
<li>
定义

<ol>
<li>
键必须是唯一的，而值不一定是唯一的。

<li>
每个值必须与键相关联，但键可能没有值

<li>
对键进行明确定义非常重要。它决定了计数是否区分大小写，这将产生不同的结果。

</ol>
<li>
为什么采用键/值数据

<ol>
<li>
键值数据这一简单的模型具有广泛的适用性。

<li>
MapReduce利用其键值接口提供了这样的抽象：程序员只需指定所要求的转换，Hadoop完成对任意规模数据集的复杂的数据转换处理过程。

</ol>
<li>
实际应用<br/>
  日常生活中有很多例子

</ul>
  
<h4 id="toc_0.0.1.2">MapReduce 过程</h4>
<ol>
<li>
启动

<ul>
<li>
JobTracker负责作业调度和执行的各个方面，它代表了我们与NameNode通信，并对储存在HDFS上的数据相关的所有交互进行管理。

</ul>
<li>
将输入分块

<ul>
<li>
这些交互首先发生在JobTracker接受输入数据，并确定如何将其分配给map任务的时候。HDFS文件通常被分成至少64MB的数据块，JobTracker会将每个数据块分配给一个map任务。

</ul>
<li>
任务分配

<ul>
<li>
一旦JobTracker确定了所需的map任务数，它就会检查集群中的主机数，正在运行的TaskTracker数以及可并发执行的map任务数。

</ul>
<li>
任务启动

<ol>
<li>
如果集群有足够的能力一次性执行所有的map任务，它们将会被全部启动，并获得它们将要处理的分块数据和作业JAR文件。

<li>
如果任务数超过了集群能力，JobTracker将维护一个挂起任务队列，并在节点完成最初分配的map任务后，将挂起的任务分配给节点。

<li>
获取数据

</ol>
<li>
不断监视JobTracker

<ol>
<li>
现在JobTracker等待TaskTracker执行所有的mapper和reducer。它不断地与TaskTracker交换心跳和状态信息，查找进度或问题的证据。它还从整个作业执行过程的所有任务中收集指标，其中一些指标是Hadoop提供的，还有一些是map和reduce任务的开发人员指定的。

</ol>
</ol>
 
<h1 id="toc_1">JAVA东西太多了，跳过了，回到首页<a href="Hadoop.html">Hadoop</a></h1>

</body>
</html>
